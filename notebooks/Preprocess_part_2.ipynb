{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:13:35.406749Z",
     "start_time": "2022-08-13T17:13:34.916015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import geopandas as gpd\n",
    "import openpyxl\n",
    "import os\n",
    "random.seed(10)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:13:35.415778Z",
     "start_time": "2022-08-13T17:13:35.409193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in taxi_zones lookup table\n",
    "zones = pd.read_csv(\"../data/raw/external_data_and_taxi_zones/taxi_zone_lookup.csv\")\n",
    "zones = zones.drop([263, 264]) # drop the unknown zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess property sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:38.826255Z",
     "start_time": "2022-08-13T17:13:35.417899Z"
    }
   },
   "outputs": [],
   "source": [
    "relative_directory = '../data/raw/external_data_and_taxi_zones/'\n",
    "\n",
    "all_files = os.listdir(\"../data/raw/external_data_and_taxi_zones/\")    \n",
    "property_sale_files = list(filter(lambda x: x.endswith('.xlsx'), all_files))\n",
    "\n",
    "header = ['BOROUGH', 'NEIGHBORHOOD','BUILDING CLASS CATEGORY', \n",
    "          'TAX CLASS AT PRESENT', 'BLOCK', 'LOT', \n",
    "          'EASE-MENT', 'BUILDING CLASS AT PRESENT', 'ADDRESS',\n",
    "          'APARTMENT NUMBER', 'ZIP CODE', 'RESIDENTIAL UNITS',\n",
    "          'COMMERCIAL UNITS', 'TOTAL UNITS', 'LAND SQUARE FEET',\n",
    "          'GROSS SQUARE FEET', 'YEAR BUILT', 'TAX CLASS AT TIME OF SALE',\n",
    "          'BUILDING CLASS AT TIME OF SALE', 'SALE PRICE', 'SALE DATE']\n",
    "\n",
    "\n",
    "file_names = [relative_directory + file for file in property_sale_files]\n",
    "\n",
    "\n",
    "def read_xlxs_for_mapping(data):\n",
    "    return pd.read_excel(data, \n",
    "                        names = header, \n",
    "                        parse_dates = ['SALE DATE', ],\n",
    "                        engine = 'openpyxl')\n",
    "\n",
    "property_sales = pd.concat(map(read_xlxs_for_mapping, file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:38.832932Z",
     "start_time": "2022-08-13T17:14:38.828198Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(data, columns):\n",
    "    '''\n",
    "    remove outliers from data that is 1.5 iqr away from q1 or q3\n",
    "    '''\n",
    "    new_data = data.copy()\n",
    "    q1 = np.array([np.quantile(data[column], 0.25) for column in columns])\n",
    "    q3 = np.array([np.quantile(data[column], 0.75) for column in columns])\n",
    "    iqr = q3 - q1\n",
    "    for i in range(len(columns)):\n",
    "        column = columns[i]\n",
    "        new_data = new_data[(new_data[column] > q1[i] - 3 * iqr[i]) & (new_data[column] < q3[i] + 3 * iqr[i])]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:38.986372Z",
     "start_time": "2022-08-13T17:14:38.835144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 206017 entries, 0 to 21716\n",
      "Data columns (total 21 columns):\n",
      " #   Column                          Non-Null Count   Dtype \n",
      "---  ------                          --------------   ----- \n",
      " 0   BOROUGH                         152654 non-null  object\n",
      " 1   NEIGHBORHOOD                    152614 non-null  object\n",
      " 2   BUILDING CLASS CATEGORY         152614 non-null  object\n",
      " 3   TAX CLASS AT PRESENT            152383 non-null  object\n",
      " 4   BLOCK                           152614 non-null  object\n",
      " 5   LOT                             152614 non-null  object\n",
      " 6   EASE-MENT                       10 non-null      object\n",
      " 7   BUILDING CLASS AT PRESENT       152383 non-null  object\n",
      " 8   ADDRESS                         152614 non-null  object\n",
      " 9   APARTMENT NUMBER                33410 non-null   object\n",
      " 10  ZIP CODE                        152589 non-null  object\n",
      " 11  RESIDENTIAL UNITS               122566 non-null  object\n",
      " 12  COMMERCIAL UNITS                122566 non-null  object\n",
      " 13  TOTAL UNITS                     122566 non-null  object\n",
      " 14  LAND SQUARE FEET                122566 non-null  object\n",
      " 15  GROSS SQUARE FEET               122566 non-null  object\n",
      " 16  YEAR BUILT                      141743 non-null  object\n",
      " 17  TAX CLASS AT TIME OF SALE       152614 non-null  object\n",
      " 18  BUILDING CLASS AT TIME OF SALE  152614 non-null  object\n",
      " 19  SALE PRICE                      152614 non-null  object\n",
      " 20  SALE DATE                       206012 non-null  object\n",
      "dtypes: object(21)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "property_sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:39.437043Z",
     "start_time": "2022-08-13T17:14:38.988041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove irrelevant rows\n",
    "property_sales = property_sales[property_sales['BOROUGH'].isin(['1', '2', '3', '4', '5'])]\n",
    "\n",
    "# Drop rows with NaN valus in required fields\n",
    "property_sales.dropna(how='any', subset=['BOROUGH', 'NEIGHBORHOOD', 'BUILDING CLASS AT PRESENT',\n",
    "                                         'TOTAL UNITS', 'GROSS SQUARE FEET', 'BUILDING CLASS AT TIME OF SALE', \n",
    "                                         'SALE PRICE', 'SALE DATE'], inplace=True)\n",
    "\n",
    "# Change data type\n",
    "property_sales['BOROUGH'] = property_sales['BOROUGH'].astype(int)\n",
    "property_sales['SALE DATE'] = pd.to_datetime(property_sales['SALE DATE'])\n",
    "property_sales['SALE PRICE'] = pd.to_numeric(property_sales['SALE PRICE'])\n",
    "property_sales['GROSS SQUARE FEET'] = pd.to_numeric(property_sales['GROSS SQUARE FEET'])\n",
    "property_sales['TOTAL UNITS'] = pd.to_numeric(property_sales['TOTAL UNITS'])\n",
    "\n",
    "\n",
    "# According to property sales data, 1 for man, 2 for bronx, 3 for brooklyn, 4 for queens, 5 for staten island\n",
    "borough_dict = {4: 'Queens', 2: 'Bronx', 1: 'Manhattan', 5: 'Staten Island', 3: 'Brooklyn'}\n",
    "property_sales['BOROUGH'] = property_sales['BOROUGH'].apply(lambda x: borough_dict[x])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter data that fits our analysis\n",
    "# Type ABCD are family dwellings and apartments, H is hotel\n",
    "condition = (property_sales['SALE DATE'] > '01-01-2019') & (property_sales['SALE DATE'] <= '29-02-2020') &\\\n",
    "            (property_sales['SALE PRICE'] > 0) &\\\n",
    "            (property_sales['GROSS SQUARE FEET'] > 0) &\\\n",
    "            (property_sales['TOTAL UNITS'] > 0) &\\\n",
    "            (property_sales['BUILDING CLASS AT PRESENT'] == property_sales['BUILDING CLASS AT TIME OF SALE']) &\\\n",
    "            (property_sales['BUILDING CLASS AT TIME OF SALE'].str.contains('^[ABCDH]', regex=True))\n",
    "\n",
    "\n",
    "property_sales = property_sales.loc[condition]\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "property_sales.drop(columns = ['BUILDING CLASS CATEGORY', 'TAX CLASS AT PRESENT', 'BLOCK', \n",
    "                               'LOT', 'EASE-MENT', 'BUILDING CLASS AT PRESENT', \n",
    "                               'ADDRESS', 'APARTMENT NUMBER', 'ZIP CODE', \n",
    "                               'RESIDENTIAL UNITS', 'COMMERCIAL UNITS', \n",
    "                               'LAND SQUARE FEET', 'YEAR BUILT', 'TAX CLASS AT TIME OF SALE'], inplace=True)\n",
    "\n",
    "\n",
    "# Add 'PRICE PER UNIT' and 'PRICE PER SQUARE FEET' as features\n",
    "\n",
    "property_sales['PRICE PER UNIT'] = property_sales['SALE PRICE'] / property_sales['TOTAL UNITS']\n",
    "\n",
    "property_sales['PRICE PER SQUARE FEET'] = property_sales['SALE PRICE'] / property_sales['GROSS SQUARE FEET']\n",
    "\n",
    "# Assume the numeric data are normally distributed, remove the outliers\n",
    "property_sales = remove_outliers(property_sales, ['SALE PRICE', 'GROSS SQUARE FEET', 'TOTAL UNITS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:39.456863Z",
     "start_time": "2022-08-13T17:14:39.438865Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate results\n",
    "\n",
    "aggregated_sales_2019 = property_sales[(property_sales['SALE DATE'] > '01-01-2019') & \\\n",
    "                                       (property_sales['SALE DATE'] <= '31-12-2019')] \\\n",
    "                        .groupby(['NEIGHBORHOOD'], as_index = False).mean()\n",
    "\n",
    "aggregated_sales_2020 = property_sales[(property_sales['SALE DATE'] > '01-01-2020') & \\\n",
    "                                       (property_sales['SALE DATE'] <= '29-02-2020')] \\\n",
    "                        .groupby(['NEIGHBORHOOD'], as_index = False).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:40.100618Z",
     "start_time": "2022-08-13T17:14:39.458738Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data linkage has 235 matches'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Link taxi zones data to property sales data based on their name of locations\n",
    "# for taxi zones data is the 'Zone', for property sales data is the 'Neighborhood'\n",
    "\n",
    "def t(name):\n",
    "    \"\"\"\n",
    "    return a transformed zone name that is splitted into several parts\n",
    "    \"\"\"\n",
    "    name = name.lower()\n",
    "    name = re.sub('[\\/\\-0-9()]+', ' ', name)\n",
    "    names = name.split()\n",
    "    return names\n",
    "\n",
    "\n",
    "\n",
    "def link(name1, name_list_2, threshold_confidence):\n",
    "    \"\"\"\n",
    "    return a possible match of name1 from name_list_2\n",
    "    \"\"\"\n",
    "    confident_pairs = [[(name1, name2),\n",
    "                        len(set(t(name1)).intersection(t(name2))) \n",
    "                        / len(t(name1))\n",
    "                        ] \\\n",
    "                        for name2 in name_list_2]\n",
    "    max_confidence = max([confidence for pair, confidence in confident_pairs])\n",
    "    most_confident_pairs = [pair for pair, confidence in confident_pairs if confidence == max_confidence]\n",
    "    number_of_most_confident_pairs = len(most_confident_pairs)\n",
    "    if max_confidence >= threshold_confidence:\n",
    "        # we randomly choose one pair, because if two zones have similar names they are likely \n",
    "        # to have similar locations\n",
    "        return most_confident_pairs[random.randint(0, len(most_confident_pairs) - 1)][1]\n",
    "\n",
    "\n",
    "\n",
    "# Find the corresponding neighborhood to each taxi zone\n",
    "zones_dict = {}\n",
    "for zone in zones['Zone'].unique():\n",
    "    zones_dict[zone] = link(zone, \n",
    "                            property_sales['NEIGHBORHOOD'].unique(), \n",
    "                            threshold_confidence = 0.25) # set a low threshold confidence to get high recall\n",
    "\n",
    "\n",
    "\n",
    "zones['Neighborhood'] = zones['Zone'].apply(lambda x: zones_dict[x])\n",
    "f'Data linkage has {len([i for i in zones_dict.values() if i != None])} matches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:40.111116Z",
     "start_time": "2022-08-13T17:14:40.102292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "      <th>Neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "      <td>AIRPORT LA GUARDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "      <td>JAMAICA BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "      <td>PELHAM GARDENS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "      <td>ARDEN HEIGHTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone  \\\n",
       "0           1            EWR           Newark Airport          EWR   \n",
       "1           2         Queens              Jamaica Bay    Boro Zone   \n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone   \n",
       "3           4      Manhattan            Alphabet City  Yellow Zone   \n",
       "4           5  Staten Island            Arden Heights    Boro Zone   \n",
       "\n",
       "         Neighborhood  \n",
       "0  AIRPORT LA GUARDIA  \n",
       "1         JAMAICA BAY  \n",
       "2      PELHAM GARDENS  \n",
       "3       ALPHABET CITY  \n",
       "4       ARDEN HEIGHTS  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some errors still exist but not a big problem\n",
    "zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:40.137548Z",
     "start_time": "2022-08-13T17:14:40.112828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Join the taxi zones with property sales\n",
    "zones_2019 = zones.merge(aggregated_sales_2019, left_on = ['Neighborhood'], right_on = ['NEIGHBORHOOD'], how = 'left')\n",
    "zones_2020 = zones.merge(aggregated_sales_2020, left_on = ['Neighborhood'], right_on = ['NEIGHBORHOOD'], how = 'left')\n",
    "\n",
    "# Fill na with Borough mean if the Neighborhood is not found\n",
    "for i in range(6, 11):\n",
    "    col = zones_2019.columns[i]\n",
    "    zones_2019[col] = zones_2019[col].fillna(zones_2019.groupby('Borough')[col].transform('mean'))\n",
    "    zones_2020[col] = zones_2020[col].fillna(zones_2020.groupby('Borough')[col].transform('mean'))\n",
    "    \n",
    "    \n",
    "selected_columns = ['LocationID', 'TOTAL UNITS', \n",
    "                    'GROSS SQUARE FEET', 'SALE PRICE', \n",
    "                    'PRICE PER UNIT', 'PRICE PER SQUARE FEET']\n",
    "\n",
    "renamed_columns = {'TOTAL UNITS': 'Total_units', \n",
    "                   'GROSS SQUARE FEET': 'Gross_square_feet', \n",
    "                   'SALE PRICE': 'Sale_price',\n",
    "                   'PRICE PER UNIT': 'Price_per_unit', \n",
    "                   'PRICE PER SQUARE FEET': 'Price_per_square_feet'}\n",
    "    \n",
    "zones_2019 = zones_2019[selected_columns].rename(columns = renamed_columns)\n",
    "zones_2020 = zones_2020[selected_columns].rename(columns = renamed_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:40.779760Z",
     "start_time": "2022-08-13T17:14:40.138901Z"
    }
   },
   "outputs": [],
   "source": [
    "# read in population by neigborhood data and its shape file\n",
    "population = pd.read_csv(relative_directory + 'nyc_population_by_neighborhood.csv')\n",
    "population_sf = gpd.read_file(\"../data/raw/external_data_and_taxi_zones/nynta2010_22b/nynta2010.shp\")\n",
    "\n",
    "# read in taxi zones shape file\n",
    "zones_sf = gpd.read_file(\"../data/raw/external_data_and_taxi_zones/taxi_zones/taxi_zones.shp\")\n",
    "zones_sf['geometry'] = zones_sf['geometry'].to_crs(2830) # 2830 is the EPSG code for New York\n",
    "zones_gdf = gpd.GeoDataFrame(\n",
    "    pd.merge(zones, zones_sf, on='LocationID', how='inner')\n",
    ")\n",
    "zones_gdf = zones_gdf.drop_duplicates('LocationID') # Drop duplicated id\n",
    "\n",
    "# Convert the geometry shape to to latitude and longitude\n",
    "population_sf['geometry'] = population_sf['geometry'].to_crs(2830)\n",
    "\n",
    "# we will use only 2010 data\n",
    "population = population[population['Year'] == 2010]\n",
    "\n",
    "# Merge\n",
    "population_gdf = gpd.GeoDataFrame(\n",
    "    pd.merge(population, population_sf, left_on = 'NTA Code', right_on = 'NTACode', how='inner')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Since the metadata does not specify the unit of the areas, but we know that the area of New York is 783.8 km2. <br>\n",
    "By trying out a few units, we can deduce that the internal unit is square foot. The size of New York in square feet is about 8.43675e+9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:40.784733Z",
     "start_time": "2022-08-13T17:14:40.781199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York is 8.42299e+09 square feet large'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"New York is {population_gdf['Shape_Area'].sum():.6} square feet large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess population data (continue.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:40.791615Z",
     "start_time": "2022-08-13T17:14:40.786214Z"
    }
   },
   "outputs": [],
   "source": [
    "population_gdf['Shape_Area'] = population_gdf['Shape_Area'] / 27878400 # change square feet to square miles\n",
    "population_gdf = population_gdf[['NTA Code', 'Population', 'Shape_Area', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:41.803982Z",
     "start_time": "2022-08-13T17:14:40.793302Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the interceptions of all area between neighborhood and service zones\n",
    "merged = gpd.overlay(zones_gdf, population_gdf, how = 'intersection', keep_geom_type = True)\n",
    "merged = merged[['LocationID', 'NTA Code', 'Shape_Area_2', \n",
    "                 'Population', 'geometry' \n",
    "                ]].rename(columns = {'Shape_Area_2': 'Area_in_square_miles', 'NTA Code': 'NTA_Code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:41.825851Z",
     "start_time": "2022-08-13T17:14:41.805477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assume that population in each NTA are evenly distributed\n",
    "\n",
    "# Merge again with the population_sf to calculate the proportion of intersection in NTA\n",
    "merged = pd.merge(merged, population_sf, \n",
    "                  left_on = 'NTA_Code', right_on = 'NTACode', \n",
    "                  how='inner', \n",
    "                  suffixes=('_merged', '_population'))\n",
    "\n",
    "merged['area_proportion'] = merged['geometry_merged'].area / merged['geometry_population'].area\n",
    "merged['Partial_Population'] = merged['Population'] * merged['area_proportion']\n",
    "merged['Population_By_LocationID'] = merged.groupby('LocationID')['Partial_Population'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:41.844715Z",
     "start_time": "2022-08-13T17:14:41.827436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finalise the preprocessing for population data\n",
    "zones_population = pd.merge(zones_gdf, merged, on = 'LocationID', how = 'left')\n",
    "\n",
    "zones_population['Density_per_square_metre'] =  zones_population['Population_By_LocationID'] \\\n",
    "                                                / zones_population['geometry'].area\n",
    "zones_population = zones_population[['LocationID', 'Population_By_LocationID', 'Density_per_square_metre']]\n",
    "zones_population.drop_duplicates(inplace = True)\n",
    "zones_population.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:41.863080Z",
     "start_time": "2022-08-13T17:14:41.846571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine population infomation with taxi zones and property sales\n",
    "new_zones_2019 = pd.merge(zones_2019, zones_population, on = 'LocationID', how = 'inner')\n",
    "new_zones_2020 = pd.merge(zones_2020, zones_population, on = 'LocationID', how = 'inner')\n",
    "\n",
    "# Write out the files\n",
    "new_zones_2019.to_csv(\"../data/curated/new_zones_2019.csv\", index = False)\n",
    "new_zones_2020.to_csv(\"../data/curated/new_zones_2020.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:41.875490Z",
     "start_time": "2022-08-13T17:14:41.864642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Total_units</th>\n",
       "      <th>Gross_square_feet</th>\n",
       "      <th>Sale_price</th>\n",
       "      <th>Price_per_unit</th>\n",
       "      <th>Price_per_square_feet</th>\n",
       "      <th>Population_By_LocationID</th>\n",
       "      <th>Density_per_square_metre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1,459.20</td>\n",
       "      <td>831,000.00</td>\n",
       "      <td>658,500.00</td>\n",
       "      <td>599.66</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1,728.00</td>\n",
       "      <td>473,214.29</td>\n",
       "      <td>303,035.71</td>\n",
       "      <td>294.48</td>\n",
       "      <td>176.83</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1,950.72</td>\n",
       "      <td>582,088.33</td>\n",
       "      <td>466,184.68</td>\n",
       "      <td>307.00</td>\n",
       "      <td>28,902.34</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4,154.00</td>\n",
       "      <td>600,000.00</td>\n",
       "      <td>150,000.00</td>\n",
       "      <td>144.44</td>\n",
       "      <td>25,123.60</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1,565.75</td>\n",
       "      <td>454,392.92</td>\n",
       "      <td>411,766.36</td>\n",
       "      <td>293.74</td>\n",
       "      <td>25,233.23</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>259</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1,884.46</td>\n",
       "      <td>476,704.42</td>\n",
       "      <td>306,228.19</td>\n",
       "      <td>270.59</td>\n",
       "      <td>42,466.74</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>260</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1,857.74</td>\n",
       "      <td>852,615.26</td>\n",
       "      <td>537,847.56</td>\n",
       "      <td>493.52</td>\n",
       "      <td>45,107.94</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>261</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2,664.27</td>\n",
       "      <td>759,143.49</td>\n",
       "      <td>387,088.11</td>\n",
       "      <td>328.53</td>\n",
       "      <td>7,241.92</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>262</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1,804.43</td>\n",
       "      <td>734,973.24</td>\n",
       "      <td>484,928.18</td>\n",
       "      <td>421.67</td>\n",
       "      <td>39,675.98</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>263</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1,788.78</td>\n",
       "      <td>475,981.70</td>\n",
       "      <td>364,272.85</td>\n",
       "      <td>283.37</td>\n",
       "      <td>37,898.23</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LocationID  Total_units  Gross_square_feet  Sale_price  Price_per_unit  \\\n",
       "0             1         1.40           1,459.20  831,000.00      658,500.00   \n",
       "1             2         1.57           1,728.00  473,214.29      303,035.71   \n",
       "2             3         1.36           1,950.72  582,088.33      466,184.68   \n",
       "3             4         4.00           4,154.00  600,000.00      150,000.00   \n",
       "4             5         1.13           1,565.75  454,392.92      411,766.36   \n",
       "..          ...          ...                ...         ...             ...   \n",
       "255         259         1.70           1,884.46  476,704.42      306,228.19   \n",
       "256         260         1.84           1,857.74  852,615.26      537,847.56   \n",
       "257         261         2.08           2,664.27  759,143.49      387,088.11   \n",
       "258         262         1.72           1,804.43  734,973.24      484,928.18   \n",
       "259         263         1.44           1,788.78  475,981.70      364,272.85   \n",
       "\n",
       "     Price_per_square_feet  Population_By_LocationID  Density_per_square_metre  \n",
       "0                   599.66                       nan                       nan  \n",
       "1                   294.48                    176.83                      0.00  \n",
       "2                   307.00                 28,902.34                      0.01  \n",
       "3                   144.44                 25,123.60                      0.03  \n",
       "4                   293.74                 25,233.23                      0.01  \n",
       "..                     ...                       ...                       ...  \n",
       "255                 270.59                 42,466.74                      0.01  \n",
       "256                 493.52                 45,107.94                      0.01  \n",
       "257                 328.53                  7,241.92                      0.02  \n",
       "258                 421.67                 39,675.98                      0.06  \n",
       "259                 283.37                 37,898.23                      0.06  \n",
       "\n",
       "[260 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the processed data\n",
    "new_zones_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## about how to get this data\n",
    "1. Open https://www.visualcrossing.com/weather/weather-data-services\n",
    "2. Create a free acount with 1,000 rows queries available\n",
    "3. Summit the query for New York City weather from January 1st to December 31st of 2019\n",
    "4. Summit the query for New York City weather from January 1st to February 29th of 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:41.906121Z",
     "start_time": "2022-08-13T17:14:41.877260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the weather data\n",
    "weather_2019 = pd.read_csv(\"../data/raw/external_data_and_taxi_zones/nyc_weather_2019_Jan_to_Dec.csv\",\n",
    "                           parse_dates = ['datetime', ])\n",
    "weather_2020 = pd.read_csv(\"../data/raw/external_data_and_taxi_zones/nyc_weather_2020_Jan_to_Feb.csv\",\n",
    "                           parse_dates = ['datetime', ])\n",
    "\n",
    "# Using feelslike temperature is more suitable in the case of tip amount analysis\n",
    "selected_columns = ['month', 'day_of_month', 'feelslike', \n",
    "                    'feelslikemax', 'feelslikemin', 'feelslike_temp_diff',\n",
    "                    'precip', 'precipcover', 'snow', \n",
    "                    'snowdepth', 'windspeed', 'cloudcover', 'visibility'\n",
    "                   ]\n",
    "\n",
    "def transform_weather_data(weather):\n",
    "    weather['day_of_month'] = weather['datetime'].dt.day\n",
    "    weather['month'] = weather['datetime'].dt.month\n",
    "    weather['feelslike_temp_diff'] = weather['feelslikemax'] - weather['feelslikemin']\n",
    "    weather = weather[selected_columns]\n",
    "    return weather\n",
    "\n",
    "weather_2019 = transform_weather_data(weather_2019)\n",
    "weather_2020 = transform_weather_data(weather_2020)\n",
    "\n",
    "\n",
    "# Write out the files\n",
    "weather_2019.to_csv(\"../data/curated/weather_2019.csv\", index = False)\n",
    "weather_2020.to_csv(\"../data/curated/weather_2020.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-13T17:14:41.920297Z",
     "start_time": "2022-08-13T17:14:41.908094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>feelslikemax</th>\n",
       "      <th>feelslikemin</th>\n",
       "      <th>feelslike_temp_diff</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipcover</th>\n",
       "      <th>snow</th>\n",
       "      <th>snowdepth</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.60</td>\n",
       "      <td>14.60</td>\n",
       "      <td>1.20</td>\n",
       "      <td>13.40</td>\n",
       "      <td>7.57</td>\n",
       "      <td>29.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.90</td>\n",
       "      <td>68.70</td>\n",
       "      <td>13.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>3.80</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.60</td>\n",
       "      <td>48.20</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.20</td>\n",
       "      <td>6.40</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.20</td>\n",
       "      <td>66.10</td>\n",
       "      <td>15.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.90</td>\n",
       "      <td>7.70</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.20</td>\n",
       "      <td>29.90</td>\n",
       "      <td>15.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.30</td>\n",
       "      <td>8.10</td>\n",
       "      <td>1.80</td>\n",
       "      <td>6.30</td>\n",
       "      <td>11.93</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.20</td>\n",
       "      <td>78.50</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>9.40</td>\n",
       "      <td>12.20</td>\n",
       "      <td>5.70</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.60</td>\n",
       "      <td>70.80</td>\n",
       "      <td>15.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>7.30</td>\n",
       "      <td>10.30</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.80</td>\n",
       "      <td>27.70</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>3.40</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>5.92</td>\n",
       "      <td>29.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.70</td>\n",
       "      <td>63.50</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.10</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>3.90</td>\n",
       "      <td>17.08</td>\n",
       "      <td>87.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.90</td>\n",
       "      <td>95.80</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>2.30</td>\n",
       "      <td>4.90</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.38</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>83.50</td>\n",
       "      <td>15.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day_of_month  feelslike  feelslikemax  feelslikemin  \\\n",
       "0        1             1       8.60         14.60          1.20   \n",
       "1        1             2      -0.20          3.80         -2.30   \n",
       "2        1             3       2.20          6.40         -0.90   \n",
       "3        1             4       1.90          7.70         -2.10   \n",
       "4        1             5       3.30          8.10          1.80   \n",
       "..     ...           ...        ...           ...           ...   \n",
       "360     12            27       9.40         12.20          5.70   \n",
       "361     12            28       7.30         10.30          5.60   \n",
       "362     12            29       3.40          6.20          1.00   \n",
       "363     12            30       0.00          2.10         -1.80   \n",
       "364     12            31       2.30          4.90         -1.40   \n",
       "\n",
       "     feelslike_temp_diff  precip  precipcover  snow  snowdepth  windspeed  \\\n",
       "0                  13.40    7.57        29.17  0.00       0.00      39.90   \n",
       "1                   6.10    0.00         0.00  0.00       0.00      21.60   \n",
       "2                   7.30    0.00         0.00  0.00       0.00      33.20   \n",
       "3                   9.80    0.00         0.00  0.00       0.00      26.20   \n",
       "4                   6.30   11.93        75.00  0.00       0.00      29.20   \n",
       "..                   ...     ...          ...   ...        ...        ...   \n",
       "360                 6.50    0.00         0.00  0.00       0.00      19.60   \n",
       "361                 4.70    0.00         0.00  0.00       0.00      16.80   \n",
       "362                 5.20    5.92        29.17  0.00       0.00      14.70   \n",
       "363                 3.90   17.08        87.50  0.00       0.00      38.90   \n",
       "364                 6.30    0.38         4.17  0.00       0.00      23.10   \n",
       "\n",
       "     cloudcover  visibility  \n",
       "0         68.70       13.70  \n",
       "1         48.20       16.00  \n",
       "2         66.10       15.90  \n",
       "3         29.90       15.90  \n",
       "4         78.50        8.80  \n",
       "..          ...         ...  \n",
       "360       70.80       15.70  \n",
       "361       27.70       14.10  \n",
       "362       63.50       13.00  \n",
       "363       95.80        6.10  \n",
       "364       83.50       15.40  \n",
       "\n",
       "[365 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the processed data\n",
    "weather_2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
